version: '3.7'
services:
  crawler:
    build:
      context: .
      dockerfile: Dockerfile
    entrypoint: "python /crawler/edgar/crawler-go.py "
    env_file:
      - .env
    restart: always
    links:
      - elasticsearch
    command: "positions"
  stockinfo:
    build:
      context: .
      dockerfile: Dockerfile
    entrypoint: "python /crawler/edgar/crawler-go.py "
    command: "stockinfo"
    env_file:
      - .env
    restart: always
    links:
      - elasticsearch
  elasticsearch:
    image: elasticsearch:7.6.1
    container_name: 13fes
    environment:
      - discovery.type=single-node
      - 'path.repo=/usr/share/elasticsearch/backup'
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elastic-data:/usr/share/elasticsearch/data
      - elastic-backup:/usr/share/elasticsearch/backup
  kibana:
    container_name: 13fkibana
    image: kibana:7.6.1
    shm_size: 5g
    ports:
      - "5601:5601"
    depends_on:
        - elasticsearch

volumes:
  elastic-data:
    driver: local
  elastic-backup:
    driver: local




networks:
  default:
    name: 13fnet